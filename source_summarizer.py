from openai import OpenAI
import os
import re
from dotenv import load_dotenv

load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

FULL_TME_LINK_RE = re.compile(r"^https://t\.me/(?:c/\d+|[A-Za-z0-9_]+)/\d+$")
GENERIC_URL_RE = re.compile(r"^https?://\S+$")


def _unique_keep_order(items):
    seen = set()
    out = []
    for x in items:
        if x and x not in seen:
            seen.add(x)
            out.append(x)
    return out


def _strip_output_links_section(text: str) -> str:
    lines = (text or "").splitlines()
    cleaned = []
    in_links_section = False

    for line in lines:
        s = line.strip()

        if s.replace(" ", "") == "ì›ë¬¸ì¶œì²˜ë§í¬":
            in_links_section = True
            continue

        if in_links_section:
            if not s:
                continue
            if s.startswith("http://") or s.startswith("https://"):
                continue
            in_links_section = False

        if s.startswith("http://") or s.startswith("https://"):
            continue

        cleaned.append(line)

    return "\n".join(cleaned).strip()


def summarize_source(source_name, messages):
    combined_list = []
    links = []

    for m in messages[:100]:
        text = m.get("text") or ""
        link = m.get("link")

        if link:
            combined_list.append(f"{text}\n(ì¶œì²˜: {link})")
            link = link.strip()

            if link.startswith("https://t.me/"):
                if FULL_TME_LINK_RE.match(link):
                    links.append(link)
            else:
                if GENERIC_URL_RE.match(link):
                    links.append(link)
        else:
            combined_list.append(text)

    combined = "\n\n".join(combined_list)

    prompt = f"""
    ì•„ë˜ëŠ” í…”ë ˆê·¸ë¨ ì±„ë„ '{source_name}'ì˜ ìµœê·¼ 24ì‹œê°„ ë©”ì‹œì§€ë‹¤.

    ì´ ì±„ë„ì´ ì˜¤ëŠ˜ ë‹¤ë£¬ ë‚´ìš©ì„ í•˜ë‚˜ì˜ ë¶„ì„ ë¦¬í¬íŠ¸ í˜•íƒœë¡œ ì‘ì„±í•˜ë¼.

    êµ¬ì„±:
    1. ğŸ“¡ ì±„ë„ëª…
    2. ì˜¤ëŠ˜ í•µì‹¬ ì£¼ì œ 3~5ê°œ (ê° ì£¼ì œëŠ” ì§§ì€ ì†Œì œëª© + ì„¤ëª…)
    3. ì „ë°˜ì ì¸ í•µì‹¬ íë¦„ ìš”ì•½

    ì¡°ê±´:
    - 800~1400ì ë¶„ëŸ‰
    - HTML í˜•ì‹
    - ì´ëª¨ì§€ ì ì ˆíˆ ì‚¬ìš©
    - ë‰´ìŠ¤ ë‚˜ì—´ ê¸ˆì§€
    - ì±„ë„ ë‚´ ë…¼ì˜ íë¦„ ì¤‘ì‹¬ìœ¼ë¡œ ì¬êµ¬ì„±
    - ì–´ë ¤ìš´ ê²½ì œ, ê¸°ìˆ ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ ì„¤ëª…
    - ì°¸ê³ í•œ ë§í¬ë„ í•˜ë‹¨ì— ì²¨ë¶€(ì°¸ê³  ë§í¬ëŠ” ë°˜ë“œì‹œ "ì›ë¬¸ ì¶œì²˜ ë§í¬" ì„¹ì…˜ì— ì œê³µëœ URLë§Œ ì‚¬ìš©í•˜ë¼.ë©”ì‹œì§€ ë³¸ë¬¸ì— í¬í•¨ëœ URLì€ ì ˆëŒ€ ì°¸ê³  ë§í¬ë¡œ í¬í•¨í•˜ì§€ ë§ˆë¼.ìƒˆë¡œìš´ URLì„ ìƒì„±í•˜ì§€ ë§ˆë¼.)

    ì•„ë˜ëŠ” í…”ë ˆê·¸ë¨ ì±„ë„ì˜ ìµœê·¼ 24ì‹œê°„ ë©”ì‹œì§€ë‹¤.

    âš ï¸ ì ˆëŒ€ HTML íƒœê·¸ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆë¼.
    âš ï¸ <html>, <body>, <ul>, <li>, <p> ë“± ì–´ë–¤ íƒœê·¸ë„ ì“°ì§€ ë§ˆë¼.
    âš ï¸ Markdownë„ ì“°ì§€ ë§ˆë¼.
    âš ï¸ êµµê²Œ í‘œì‹œë„ í•˜ì§€ ë§ˆë¼.
    âš ï¸ ì˜¤ì§ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©í•˜ë¼.
    ëŒ€ì‹  ë¬¸ë‹¨êµ¬ë¶„ ë° ë¬¸ë‹¨ê³¼ ë¬¸ë‹¨ì‚¬ì´ í•œì¤„ ë„ìš°ê¸°ë¥¼ í†µí•´ ê¸€ì˜ ê°€ë…ì„±ì„ ë†’ì—¬ë¼

    ë©”ì‹œì§€:
    {combined}
    """

    response = client.responses.create(
        model="gpt-5-mini",
        input=prompt,
    )

    out = (response.output_text or "").strip()

    # ëª¨ë¸ì´ ë§Œë“  ë§í¬/ë§í¬ì„¹ì…˜ì€ ì œê±°í•˜ê³ , ìš°ë¦¬ê°€ ìˆ˜ì§‘í•œ ë§í¬ë§Œ ë¶™ì¸ë‹¤
    out = _strip_output_links_section(out)

    links = _unique_keep_order(links)[:10]
    if links:
        out += "\n\nì›ë¬¸ ì¶œì²˜ ë§í¬\n" + "\n".join(links)

    return out