from openai import OpenAI
import os
import re
from dotenv import load_dotenv

load_dotenv()

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ì™„ì „í˜• í…”ë ˆê·¸ë¨ ë§í¬ë§Œ í—ˆìš©
# - ê³µê°œì±„ë„: https://t.me/username/12345
# - ë‚´ë¶€ë§í¬: https://t.me/c/123456789/12345
FULL_TME_LINK_RE = re.compile(r"^https://t\.me/(?:c/\d+|[A-Za-z0-9_]+)/\d+$")


def _unique_keep_order(items):
    seen = set()
    out = []
    for x in items:
        if x and x not in seen:
            seen.add(x)
            out.append(x)
    return out


def _strip_output_links_section(text: str) -> str:
    """
    ëª¨ë¸ì´ ì¶œë ¥í•œ 'ì›ë¬¸ ì¶œì²˜ ë§í¬' ì„¹ì…˜(ë° URL ë¼ì¸)ì„ ì œê±°í•´ì„œ
    ìš°ë¦¬ê°€ ê°€ì§„ ë§í¬ ëª©ë¡ìœ¼ë¡œ ë‹¤ì‹œ ë¶™ì¼ ìˆ˜ ìˆê²Œ í•¨.
    """
    lines = (text or "").splitlines()
    cleaned = []
    in_links_section = False

    for line in lines:
        s = line.strip()

        # 'ì›ë¬¸ ì¶œì²˜ ë§í¬' ì„¹ì…˜ ì‹œì‘ ê°ì§€
        if s.replace(" ", "") == "ì›ë¬¸ì¶œì²˜ë§í¬":
            in_links_section = True
            continue

        # ë§í¬ ì„¹ì…˜ ì•ˆì—ì„œëŠ” URL/ë¹ˆì¤„ë§Œ ìŠ¤í‚µí•˜ê³ , ë‹¤ë¥¸ í…ìŠ¤íŠ¸ê°€ ë‚˜ì˜¤ë©´ ì„¹ì…˜ ì¢…ë£Œ
        if in_links_section:
            if not s:
                continue
            if s.startswith("http://") or s.startswith("https://"):
                continue
            # ë§í¬ ì„¹ì…˜ì¸ë° URLì´ ì•„ë‹Œ í…ìŠ¤íŠ¸ê°€ ë‚˜ì˜¤ë©´ ì„¹ì…˜ ì¢…ë£Œí•˜ê³  ê·¸ ë¼ì¸ì€ ë³¸ë¬¸ìœ¼ë¡œ ì‚´ë¦¼
            in_links_section = False

        # ì„¹ì…˜ ë°–ì—ì„œë„ URL ë¼ì¸ì´ ì„ì´ë©´ ì œê±°(ê°€ë” ëª¨ë¸ì´ ë³¸ë¬¸ì— URLì„ ë„£ìŒ)
        if s.startswith("http://") or s.startswith("https://"):
            continue

        cleaned.append(line)

    # ë’¤ìª½ ê³µë°± ì •ë¦¬
    return "\n".join(cleaned).strip()


def summarize_source(source_name, messages):
    combined_list = []

    # âœ… ìš°ë¦¬ê°€ ë¶™ì¼ "ì •í™•í•œ ë§í¬"ëŠ” ë”°ë¡œ ëª¨ì•„ë‘ 
    links = []

    for m in messages[:100]:
        text = m["text"]
        link = m.get("link")

        if link:
            combined_list.append(f"{text}\n(ì¶œì²˜: {link})")
            # ì™„ì „í˜• ë§í¬ë§Œ ì €ì¥
            if FULL_TME_LINK_RE.match(link.strip()):
                links.append(link.strip())
        else:
            combined_list.append(text)

    combined = "\n\n".join(combined_list)

    prompt = f"""
    ì•„ë˜ëŠ” í…”ë ˆê·¸ë¨ ì±„ë„ '{source_name}'ì˜ ìµœê·¼ 24ì‹œê°„ ë©”ì‹œì§€ë‹¤.

    ì´ ì±„ë„ì´ ì˜¤ëŠ˜ ë‹¤ë£¬ ë‚´ìš©ì„ í•˜ë‚˜ì˜ ë¶„ì„ ë¦¬í¬íŠ¸ í˜•íƒœë¡œ ì‘ì„±í•˜ë¼.

    êµ¬ì„±:
    1. ğŸ“¡ ì±„ë„ëª…
    2. ì˜¤ëŠ˜ í•µì‹¬ ì£¼ì œ 3~5ê°œ (ê° ì£¼ì œëŠ” ì§§ì€ ì†Œì œëª© + ì„¤ëª…)
    3. ì „ë°˜ì ì¸ í•µì‹¬ íë¦„ ìš”ì•½

    ì¡°ê±´:
    - 800~1400ì ë¶„ëŸ‰
    - HTML í˜•ì‹
    - ì´ëª¨ì§€ ì ì ˆíˆ ì‚¬ìš©
    - ë‰´ìŠ¤ ë‚˜ì—´ ê¸ˆì§€
    - ì±„ë„ ë‚´ ë…¼ì˜ íë¦„ ì¤‘ì‹¬ìœ¼ë¡œ ì¬êµ¬ì„±
    - ì–´ë ¤ìš´ ê²½ì œ, ê¸°ìˆ ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ ì„¤ëª…
    - ì°¸ê³ í•œ ë§í¬ë„ í•˜ë‹¨ì— ì²¨ë¶€(ì°¸ê³  ë§í¬ëŠ” ë°˜ë“œì‹œ "ì›ë¬¸ ì¶œì²˜ ë§í¬" ì„¹ì…˜ì— ì œê³µëœ URLë§Œ ì‚¬ìš©í•˜ë¼.ë©”ì‹œì§€ ë³¸ë¬¸ì— í¬í•¨ëœ URLì€ ì ˆëŒ€ ì°¸ê³  ë§í¬ë¡œ í¬í•¨í•˜ì§€ ë§ˆë¼.ìƒˆë¡œìš´ URLì„ ìƒì„±í•˜ì§€ ë§ˆë¼.)

    ì•„ë˜ëŠ” í…”ë ˆê·¸ë¨ ì±„ë„ì˜ ìµœê·¼ 24ì‹œê°„ ë©”ì‹œì§€ë‹¤.

    âš ï¸ ì ˆëŒ€ HTML íƒœê·¸ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆë¼.
    âš ï¸ <html>, <body>, <ul>, <li>, <p> ë“± ì–´ë–¤ íƒœê·¸ë„ ì“°ì§€ ë§ˆë¼.
    âš ï¸ Markdownë„ ì“°ì§€ ë§ˆë¼.
    âš ï¸ êµµê²Œ í‘œì‹œë„ í•˜ì§€ ë§ˆë¼.
    âš ï¸ ì˜¤ì§ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©í•˜ë¼.
    ëŒ€ì‹  ë¬¸ë‹¨êµ¬ë¶„ ë° ë¬¸ë‹¨ê³¼ ë¬¸ë‹¨ì‚¬ì´ í•œì¤„ ë„ìš°ê¸°ë¥¼ í†µí•´ ê¸€ì˜ ê°€ë…ì„±ì„ ë†’ì—¬ë¼

    ë©”ì‹œì§€:
    {combined}
    """

    response = client.responses.create(
        model="gpt-5-mini",
        input=prompt,
    )

    out = (response.output_text or "").strip()

    # âœ… (í•µì‹¬) ëª¨ë¸ì´ ë§Œë“  'ì›ë¬¸ ì¶œì²˜ ë§í¬' ì„¹ì…˜/URL ë¼ì¸ ì œê±°
    out = _strip_output_links_section(out)

    # âœ… ë§í¬ëŠ” ìš°ë¦¬ê°€ ê°€ì§„ ê²ƒë§Œ "ì •í™•íˆ" ë‹¤ì‹œ ë¶™ì´ê¸°
    links = _unique_keep_order(links)[:10]  # ë„ˆë¬´ ê¸¸ì–´ì§€ë©´ ìƒìœ„ 10ê°œë§Œ
    if links:
        out += "\n\nì›ë¬¸ ì¶œì²˜ ë§í¬\n" + "\n".join(links)

    return out